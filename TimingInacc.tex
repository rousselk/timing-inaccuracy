\documentclass[a4paper,10pt]{article}

\usepackage[T1]{fontenc}
\usepackage{rotfloat}

\title{Timing Inaccuracy in MSPSim Emulator: Consequences on COOJA Simulations}
\author{
K\'evin Roussel, Ye-Qiong Song and Olivier Zendra\\
LORIA/INRIA Nancy Grand-Est,\\
Universit\'e de Lorraine,\\
615, rue du Jardin Botanique,\\
54600 Villers-l\`es-Nancy, France\\
\texttt{\{Kevin.Roussel,Ye-Qiong.Song,Olivier.Zendra\}@inria.fr}
}
\date{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                               80 COLONNES                                %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\hyphenation{MSP-Sim}

\abstract{
Simulation/emulation software frameworks are very useful tools: they provide
easy development and debugging environment; when they are based on
fine-grained simulation, such tools can also allow for easy performance
evaluation.

Such a tool is the COOJA network simulator, developed and published by the
Contiki OS project. Since it is based on the MSPSim emulator, it offers
very fine-grained (i.e.: cycle-accurate) simulation on Wireless Sensor
Network motes.

When performing our own simulations with COOJA and MSPSim, we observed timing
inconsistencies with identical experimentations made on actual hardware.
Such inaccuracies clearly impair the use of the COOJA/MSPSim framework as
an evaluation tool, at least for time-related results. We thus investigated
the issue, to evaluate the extent of the problem.

In the present paper, as our contributions, we will present the detailed
results of our investigations, as well as the consequences of this issue,
and give possible leads to fix or avoid them.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{COOJA and MSPSim}
\label{introduction}

Provided by the Contiki OS project~\cite{ContikiOS}, the COOJA network
simulator~\cite{Cooja} has become a widely used tool in the domain of
Wireless Sensor Networks (WSN). The research community especially uses
it extensively to perform simulations of small to relatively large wireless
networks of connected devices embedding sensors and/or actuators, commonly
named \emph{``motes''}, and thus to develop, debug and evaluate projects
based in the WSN technology.

The use of simulations is especially useful for performing virtual runs
on large sensor networks, comprising a large number of motes that would
be difficult, long and costly to operate with actual hardware.

COOJA itself is a Java-based application, providing three main features:
\begin{enumerate}
\item a graphical user interface (GUI, based on Java's standard Swing toolkit)
to design, run, and analyze WSN simulations;
\item simulation of the radio medium underlying the wireless communications
of sensor networks;
\item an extensible framework, which allows integration of external tools
to provide additional features to the COOJA application.
\end{enumerate}
This last feature is used to allow COOJA to actually emulate the various
motes constituting the WSNs. It indeed embeds and uses dedicated emulator
programs that perform cycle-accurate emulation of the chips with which motes
are built: microcontroller units (MCUs), radio transceivers, etc.

This emulation mechanism is one of the main strong assets of COOJA:
thanks to it, very fine-grained, precise and low-level simulations
can be performed; this is why COOJA has become a tool of choice especially
for debugging and evaluating WSN-related software (which happens to be
often based on Contiki OS).

Current versions of COOJA make use of two different emulator software
packages: Avrora for emulation of Atmel AVR-based devices, and
MSPSim~\cite{MSPSim} for emulation of TI MSP430-based devices.

Of these two emulators, MSPSim is currently the most used in literature
including COOJA-based simulations, since motes based on MSP430 MCUs are
more commonly distributed and used: we can especially think to the pervasive
TelosB/SkyMote family, or to Zolertia's Z1 platform.

We searched the literature, but we found no article related to any reported
inaccuracy in COOJA or MSPSim.

In the following paper, after the brief reminder about COOJA/MSPSim in the
present section~\ref{introduction}, our contributions will firstly
consist---in section~\ref{results}---in a detailed description of this
timing inaccuracy problem, using a significant set of comparisons between
simulations and experimentations on hardware; we will then use these results
to provide clues about the origin of this issue, and possible means to fix
or avoid it.
Then in section~\ref{consequences} we will see its consequences on current
WSN literature, in terms of robustness and reliability of the articles
relying on such simulations. Finally, in section~\ref{conclusion}
we will draw some conclusions from all of these contributions as an end
to the present article.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Observed Timing Inaccuracy Problem in MSPSim}
\label{results}

When performing our own simulations with virtual networks of MSP430-based
motes, we noticed timing inaccuracies in comparison to experiences made
on actual hardware. More precisely, we noticed that our simulations showed
unexplained delays during packet transmission (TX) over the radio medium,
that weren't observed during similar experiences on physical motes.
We then investigated the problem, and discovered the following results.

The problem concerns the emulation of radio-enabled, MSP430-powered WSN
devices (a.k.a. ``motes'') by the MSPSim software package.

The differences appear on one precise operation: when loading packet data
into the transmission (TX) buffer of the emulated radio transceiver---a TI
CC2420 in the case of the hardware platforms studied in the present paper.

MSPSim, when emulating the mote, performs this TX buffer loading at
a different speed than the actual hardware.

Thus, we wrote a simple example program, whose only role is to load data
packets of various sizes, chosen amongst:
\begin{itemize}
\item \emph{moderate} size, with a payload of 30 bytes;
\item \emph{medium} size, with a payload of 60 bytes;
\item \emph{large} size, with a payload of 110 bytes (that is:
      near the maximum size for IEEE 802.15.4\footnotemark[1] data packets).
\end{itemize}
\footnotetext[1]{IEEE 802.15.4 is the standard defining the physical
layer (PHY) that the involved CC2420 radio transceiver---as well as
many others---communicates on. The total maximum size for 802.15.4
packets is 127 bytes.}
This program has been compiled for, and run on MSP430- and CC2420-based
hardware platforms, that is: SkyMote/TelosB, and Zolertia Z1 motes.
The results of the comparison between execution on simulated motes
in COOJA/MSPSim and on physical hardware are shown in
Table~\ref{TblTXPktLoadDelays} hereafter.

\newcommand{\ticks}[1]{#1}
\newcommand{\moy}[1]{$\mu=$ \ticks{#1}}
\newcommand{\ect}[1]{$\sigma=$ \ticks{#1}}
\newcommand{\estus}[1]{($\approx$ #1 $\mu$sec.)}
\newcommand{\prctv}[1]{$\approx$ #1\% exp. value}

\begin{sidewaystable}[!p]
\centering

%\begin{tabular}{|l|rr|rr|rcl|}
\begin{tabular}{|l|rr|rr|rl|}
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation}
          & \multicolumn{2}{c|}{Hardware Experiment}
%          & \multicolumn{3}{c|}{Mean Difference} \\
          & \multicolumn{2}{c|}{Mean Difference} \\
\hline
 Moderate & \moy{6.4} & \ect{0.50} & \moy{7.2} & \ect{0.40}
          & \ticks{--0.8} % & \estus{24}
           & \prctv{11} \\
 Medium   & \moy{10.7} & \ect{0.46} & \moy{12.7} & \ect{0.48}
          & \ticks{--2.0} % & \estus{60}
           & \prctv{15} \\
 Large    & \moy{18.0} & \ect{0.00} & \moy{20.6} & \ect{0.49}
          & \ticks{--2.6} % & \estus{80}
           & \prctv{13} \\
\hline
\end{tabular}
\\
Results with Contiki OS on SkyMote/TelosB hardware\\
\ \\

\begin{tabular}{|l|rr|rr|rl|}
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation}
          & \multicolumn{2}{c|}{Hardware Experiment}
          & \multicolumn{2}{c|}{Mean Difference} \\
\hline
 Moderate & \moy{5.0} & \ect{0.14} & \moy{2.3} & \ect{0.44}
          & \ticks{2.8} % & \estus{84}
           & \prctv{122} \\
 Medium   & \moy{8.9} & \ect{0.27} & \moy{4.2} & \ect{0.37}
          & \ticks{4.8} % & \estus{145}
           & \prctv{114} \\
 Large    & \moy{14.0} & \ect{0.14} & \moy{7.2} & \ect{0.39}
          & \ticks{6.8} % & \estus{209}
           & \prctv{95} \\
\hline
\end{tabular}
\\
Results with Contiki OS on Z1 hardware\\
\ \\

\begin{tabular}{|l|rr|rr|rl|}
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation}
          & \multicolumn{2}{c|}{Hardware Experiment}
          & \multicolumn{2}{c|}{Mean Difference} \\
\hline
 Moderate & \moy{58.0} & \ect{0.00} & \moy{50.3} & \ect{0.46}
          & \ticks{7.7} % & \estus{235}
           & \prctv{15} \\
 Medium   & \moy{85.2} & \ect{0.39} & \moy{73.6} & \ect{0.50}
          & \ticks{11.6} % & \estus{355}
           & \prctv{16} \\
 Large    & \moy{131.2} & \ect{0.39} & \moy{111.5} & \ect{0.51}
          & \ticks{19.7} % & \estus{601}
           & \prctv{18} \\
\hline
\end{tabular}
\\
Results with RIOT OS on SkyMote/TelosB hardware\\
\ \\

\begin{tabular}{|l|rr|rr|rl|}
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation}
          & \multicolumn{2}{c|}{Hardware Experiment}
          & \multicolumn{2}{c|}{Mean Difference} \\
\hline
 Moderate & \moy{46.0} & \ect{0.00} & \moy{16.2} & \ect{0.39}
          & \ticks{29.8} % & \estus{910}
           & \prctv{184} \\
 Medium   & \moy{69.0} & \ect{0.00} & \moy{24.2} & \ect{0.39}
          & \ticks{44.8} % & \estus{1368}
           & \prctv{185} \\
 Large    & \moy{106.8} & \ect{0.39} & \moy{38.0} & \ect{0.00}
          & \ticks{68.8} % & \estus{2100}
           & \prctv{181} \\
\hline
\end{tabular}
\\
Results with RIOT OS on Z1 hardware\\
\ \\

\caption{Delays observed for loading packets into CC2420 TX buffer,
using various software platforms (i.e.: WSN operating systems).}
\label{TblTXPktLoadDelays}
\end{sidewaystable}

In Table~\ref{TblTXPktLoadDelays}, delay values are given in ``ticks'' of
\texttt{rtimer/hwtimer}, both of these timers incrementing at a rate of
32,768~Hz. The unit is thus a fixed period of time equal to about
30.5~microseconds.

\medskip

These results show that:
\begin{itemize}
\item for the Z1 hardware platform, the results are just catastrophic:
the difference between experimental and simulation values represent
100\% to almost 200\% of the actual delay! Such overestimated values
are clearly unusable for evaluation purposes;
\item for the SkyMote/Telosb, the differences are much smaller, but still
is beyond 10\%, and even 15\% for the RIOT OS setup, which is not negligible
for an accurate evaluation work; moreover, these differences can go in
both senses (that is: under- and over-estimation, while on Z1 the inaccuracy
always consists in overestimation), which makes the timing inaccuracy of
simulations quite unpredictable and thus hard to estimate and correct
without a comparison with experimentation on actual hardware.
\end{itemize}

These values are given for different operating systems---the well-known
Contiki already cited, as well as the more recent RIOT OS~\cite{RIOT}
which is also specialized in WSN---as well as for two kind of SPI drivers:
\begin{itemize}
\item a standard SPI model, which waits for every transmitted byte to be
validated by the hardware SPI interface before sending the next one:
we also call it the ``safe'' SPI access model, since it allows to detect
any problem that can occur during transmission on the SPI bus; this is
the SPI write method used by RIOT OS;
\item a so-called ``fast write'' SPI model, where a byte is written to
the bus every time the SPI hardware TX register is empty, without waiting
for the validation signals for the previous byte to be returned; this is
the SPI write method used by the Contiki OS. While this allows for faster
writes on the SPI bus, it makes transfers---at least in theory---less
reliable. (Note however that while this method dramatically accelerates
SPI transmissions to the radio transceiver, it doesn't make the timing
differences observed between simulations and hardware runs disappear
when using Contiki OS.)
\end{itemize}

For completion sake, we modified the RIOT OS SPI driver to make it use
the ``fast write'' SPI model, then performed our tests again. The results
thus obtained are shown in Table~\ref{TblDelaysModifDrivers}.

\begin{sidewaystable}[!p]
\centering

%\begin{tabular}{|l|rr|rr|rcl|}
\begin{tabular}{|l|rr|rr|rl|}
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation}
          & \multicolumn{2}{c|}{Hardware Experiment}
%          & \multicolumn{3}{c|}{Mean Difference} \\
          & \multicolumn{2}{c|}{Mean Difference} \\
\hline
 Moderate & \moy{39.2} & \ect{0.39} & \moy{38.4} & \ect{0.49}
          & \ticks{0.8} % & \estus{24}
           & \prctv{2} \\
 Medium   & \moy{53.2} & \ect{0.39} & \moy{52.8} & \ect{0.40}
          & \ticks{0.4} % & \estus{12}
           & \prctv{1} \\
 Large    & \moy{76.2} & \ect{0.39} & \moy{75.2} & \ect{0.39}
          & \ticks{1.0} % & \estus{31}
           & \prctv{1} \\
\hline
\end{tabular}
\\
Results with RIOT OS \emph{and} modified ``fast'' SPI writes
on SkyMote/TelosB hardware\\
\ \\

\begin{tabular}{|l|rr|rr|rl|}
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation}
          & \multicolumn{2}{c|}{Hardware Experiment}
          & \multicolumn{2}{c|}{Mean Difference} \\
\hline
 Moderate & \moy{27.0} & \ect{0.00} & \moy{10.0} & \ect{0.00}
          & \ticks{17.0} % & \estus{519}
           & \prctv{170} \\
 Medium   & \moy{35.0} & \ect{0.00} & \moy{13.2} & \ect{0.39}
          & \ticks{21.8} % & \estus{665}
           & \prctv{166} \\
 Large    & \moy{49.0} & \ect{0.00} & \moy{18.2} & \ect{0.39}
          & \ticks{30.8} % & \estus{941}
           & \prctv{170} \\
\hline
\end{tabular}
\\
Results with RIOT OS \emph{and} modified ``fast'' SPI writes
on Z1 hardware\\
\ \\

\caption{Delays observed for loading packets into CC2420 TX buffer,
using RIOT OS with a modified SPI driver based upon the ``fast write'' model.}
\label{TblDelaysModifDrivers}
\end{sidewaystable}

With this modified RIOT OS setup, we can see that:
\begin{itemize}
\item there is absolutely no improvement for the Z1 platform, the timing
results obtained are still overestimated by about 170\% of the actual value!
\item for the SkyMote/TelosB platform, the situation improves, leading to
the obtention of quite accurate results (2\% or less of inaccuracy).
\end{itemize}
This gives us leads about the cause of this inaccuracy problem: since it
is largely dependent on the hardware platform simulated \emph{and} the method
used to write on the SPI bus, it is probably not (mainly) due to the
emulation of the CC2420 transceiver chip, but rather to the evaluation of
the timing of SPI bus transfers, made at the MCU level. It is obvious that
the emulation of the MSP420F2617 (the MCU powering the Z1 mote) just
overestimates largely the SPI delays, while the emulation of the MSP430F1611
(from SkyMote/TelosB) performs better on that aspect.

\medskip

We thus see that whatever the software environment used, we can make the
following constatations concerning the inaccuracy in timing for the TX buffer
loading operation:
\begin{itemize}
\item for the Zolertia Z1 hardware platform, this inaccuracy is just huge:
the simulated loading delay is always 2 to 3 times larger than the actual
delay on hardware, whatever the setup (OS and SPI driver implementation)!
\item for the SkyMote/TelosB hardware platform, the inaccuracy is much less
important in absolute value, but less predictable, since it can go in both
senses: under-estimation or over-estimation of the actual delay on hardware.
Moreover, this inaccuracy can go up to 15\% of the real value (and even more
when running RIOT OS) which is not a negligible fraction.
\end{itemize}
This just makes the time-related results obtained with COOJA/MSPSim
simulations unreliable for evaluation purposes, particularly on Zolertia Z1,
but also on the very popular SkyMote/TelosB hardware platform.

Moreover, since the problem seems to be caused by the emulation of
MSP430-based MCUs by the MSPSim emulator, we expect the vast majority
of the other motes and evaluation boards emulated by the Contiki 2.7
(i.e.: latest release) version of COOJA/MSPSim framework to be also similarly
impacted by this problem, at various levels. Since we don't have specimens
of these other pieces of hardware to test, we can't provide more details.

We believe, however, that users of these devices should perform their
own tests to evaluate the possible inaccuracy and its impact on their work.
To help in that matter, we freely provide the programs we used to perform the
present work here:\\
\texttt{(URL xxxx)}.

Obviously, such a difference can be expected to have serious consequences
on the validity of evaluations made with COOJA/MSPSim simulations,
more specifically on time and performance evaluations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Consequences}
\label{consequences}

We looked in recent literature, and found many recent articles (that is:
published in year 2014 or later) using COOJA simulations to evaluate
performance of WSN projects related directly or indirectly to 802.15.4
network timing. Among them, we can cite the following:
\begin{itemize}
\item papers that exclusively rely on simulations for timing-related
performance evaluations: most use virtual SkyMote/TelosB nodes like
\cite{Constrain-Routing-Trees-2014}, \cite{Contiki-RPL-Eval-2014},
\cite{Co-RPL-2014}, \cite{DINAS-2014},
\cite{Efficient-Distrib-Svc-Discovery-2014},
\cite{IETF-Routing-WSN-2014},
\cite{TinySDN-2014}, \cite{Trickle-L2-2014},
\cite{Visual-Sensor-Networks-2014},
and \cite{RPL-GreenHouse-Convgc-Time-2014} (the latter also provides
MATLAB results, but still no actual experimental data);
while some other use different, specific MSP430-based motes
(e.g.: EXP5438 for \cite{Key-Mgmt-2015}, or WisMote for
\cite{Lightweight-Multicast-Forwarding-2014}) whose sensibility
to the present inaccuracy problem is unknown to us;
these works are the most threatened by the issue described
in the present paper;
\item papers that rely on both simulations and experimental results
for timing-related performance evaluations: we especially found
\cite{Probing-Mech-wu-2015} which also presents purely numerical,
MATLAB-produced results; such articles, (much) less common, are thus
less sensible to simulation inaccuracies, but can nonetheless present
some biased results.
\end{itemize}

Almost all of these papers present work related to high-level layers
of WSN network stacks, especially routing protocols (like
\cite{Constrain-Routing-Trees-2014}, \cite{Contiki-RPL-Eval-2014},
\cite{Co-RPL-2014}, \cite{IETF-Routing-WSN-2014},
\cite{RPL-GreenHouse-Convgc-Time-2014}, and \cite{Trickle-L2-2014})
or application-level protocols (e.g.: \cite{DINAS-2014},
\cite{Efficient-Distrib-Svc-Discovery-2014}, \cite{Key-Mgmt-2015},
and \cite{Visual-Sensor-Networks-2014}).
Some can even present alternate network stacks (\cite{TinySDN-2014}).

\medskip

Such studies, which rely on COOJA/MSPSim emulation runs to evaluate
time-related performance on WSN, have a (potentially high) risk of
suffering from inexact results due to the inaccuracy described hereabove,
which may go from a moderate bias, up to complete irrelevancy; in the latter
case, the issue obviously amounts as far as putting the discussions and
conclusions of these papers in jeopardy.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}
\label{conclusion}

In the present article, we provided the following contributions:
\begin{itemize}
\item we clearly showed that MSPSim emulation suffers from a serious timing
inaccuracy issue concerning SPI bus access, which impacts especially
communication between MCUs and radio transceivers---and thus, wireless
network operation---on WSN motes;
\item we described the extent of the problem with detailed experimentation
results---extent which happens to be serious, especially concerning the
emulation of the Zolertia Z1 hardware platform---and provided serious clues
about the cause of the issue (and consequently the way to fix it);
\item and we briefly enumerated a list of many recently published articles
in the WSN domain whose results are potentially negatively impacted by this
problem, because they rely on COOJA/MSPSim simulations to evaluate their work.
The validity of such publications may be put in jeopardy by the
issue we describe here, especially when time-related results
obtained by simulation are involved.
\end{itemize}

\medskip

Until a fix is made and published to correct this timing inaccuracy
in the MSPSim emulator, we believe the only way to get robust and reliable
results concerning timing and time-related performance evaluation is
to perform tests on actual hardware, which will eliminate any bias
that could be introduced by errors or inaccuracies in emulator software.

Of course, such hardware tests are much more difficult, long and
costly to prepare, run and analyze. That's why fixing the problem
we describe in the present paper by correcting MSPSim code should
be done as soon as possible.

Many published articles in the domain of WSNs, including very recent
and current publications, include simulations made with the COOJA/MSPSim
framework. This is clearly a testimony of the usefulness of the COOJA/MSPSim
software package. While the issue described here can impair its use as
a performance evaluation tool, it does not affect its other applications,
like the ability to develop and debug WSN-related software much more easily
thanks to its emulation features.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\vfill
\bibliographystyle{unsrt}
{\small
\bibliography{TimingInacc}}

\end{document}
