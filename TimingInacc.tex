\documentclass[10pt]{ewsn-proc}

\usepackage[T1]{fontenc}
\usepackage{balance}
\usepackage{comment}

\numberofauthors{3}
\author{
\alignauthor K\'evin Roussel \\
        \affaddr{INRIA Nancy Grand-Est}\\
        \affaddr{615, rue du Jardin Botanique}\\
        \affaddr{54600 Villers-l\`es-Nancy, France}
       \email{kevin.roussel@inria.fr}
\alignauthor Ye-Qiong Song \\
        \affaddr{LORIA/INRIA Nancy Grand-Est}\\
        \affaddr{615, rue du Jardin Botanique}\\
        \affaddr{54600 Villers-l\`es-Nancy, France}
       \email{ye-qiong.song@loria.fr}
\alignauthor Olivier Zendra \\
        \affaddr{INRIA Nancy Grand-Est}\\
        \affaddr{615, rue du Jardin Botanique}\\
        \affaddr{54600 Villers-l\`es-Nancy, France}
       \email{olivier.zendra@inria.fr}
}

\title{Timing Inaccuracy in MSPSim Emulator: Consequences on COOJA Simulations}
% Short paper for the NextMote workshop

\conferenceinfo{EWSN'16, NextMote Workshop} {February 15--17, 2016, Graz, Austria.}
\CopyrightYear{2015}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                               80 COLONNES                                %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\hyphenation{MSP-Sim}

\begin{abstract}
The COOJA/MSPSim network simulation framework is widely used for developing
and debugging, but also for performance evaluation of WSN projects.

When performing our own simulations with COOJA and MSPSim, we observed timing
inconsistencies with identical experimentations made on actual hardware.
Such inaccuracies clearly impair the use of the COOJA/MSPSim framework as
a performance evaluation tool, at least for time-related performance
parameters.

We will present in this paper, as our contributions, the detailed results of
our investigations on, as well as the consequences of this issue,
and give possible leads to fix or avoid it.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{COOJA and MSPSim}
\label{introduction}

Provided by the Contiki OS project~\cite{ContikiOS}, the COOJA network
simulator~\cite{Cooja} has become a widely used tool in the domain of
Wireless Sensor Networks (WSN). The research community especially uses
it extensively to perform simulations of small to relatively large wireless
networks of connected devices embedding sensors and/or actuators, commonly
named \emph{``motes''}, and thus to develop, debug and evaluate projects
based in the WSN technology.

The use of simulations is especially useful for performing virtual runs
on large sensor networks, comprising a large number of motes that would
be difficult, long and costly to operate with actual hardware.

COOJA itself is a Java-based application, providing three main features:
\begin{enumerate}
\item a graphical user interface (GUI, based on Java's standard Swing toolkit)
to design, run, and analyze WSN simulations;
\item simulation of the radio medium underlying the wireless communications
of sensor networks;
\item an extensible framework, which allows integration of external tools
to provide additional features to the COOJA application.
\end{enumerate}
This last feature is used to allow COOJA to actually emulate the various
motes constituting the WSNs. It indeed embeds and uses dedicated emulator
programs that perform cycle-accurate emulation of the chips with which motes
are built: microcontroller units (MCUs), radio transceivers, etc.

This emulation mechanism is one of the main strong assets of COOJA:
thanks to it, very fine-grained, precise and low-level simulations
can be performed; this is why COOJA has become a tool of choice especially
for debugging and evaluating WSN-related software (which happens to be
often based on Contiki OS).

Current versions of COOJA make use of two different emulator software
packages: Avrora for emulation of Atmel AVR-based devices, and
MSPSim~\cite{MSPSim} for emulation of TI MSP430-based devices.

Of these two emulators, MSPSim is currently the most used in literature
including COOJA-based simulations, since motes based on MSP430 MCUs are
more commonly distributed and used: we can especially think to the pervasive
TelosB/SkyMote family, or to Zolertia's Z1 platform.

We searched the literature, but we found no article related to any reported
inaccuracy in COOJA or MSPSim.

In this paper, after the brief reminder about COOJA and MSPSim in the
present section~\ref{introduction}, our contributions will firstly
consist---in section~\ref{results}---in a detailed description of this
timing inaccuracy problem, using a significant set of comparisons between
simulations and experimentations on hardware; we will then use these results
to provide clues about the origin of this issue, and possible means to fix
or avoid it.
Then in section~\ref{consequences} we will see its consequences on current
WSN literature, in terms of robustness and reliability of the articles
relying on such simulations. Finally, in section~\ref{conclusion}
we will draw some conclusions from all of these contributions as an end
to the present article.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Timing Inaccuracy Problem in MSPSim}
\label{results}

When performing our own simulations with virtual networks of MSP430-based
motes, we noticed timing inaccuracies in comparison to experiences made
on actual hardware. More precisely, we noticed that our simulations showed
unexplained delays during packet transmission (TX) over the radio medium,
that weren't observed during similar experiences on physical motes.
We then investigated the problem, and discovered the following results.

The problem is with the emulation of MSP430-powered, radio-enabled WSN
devices (a.k.a. ``motes'') by the MSPSim software package.

The differences appear on one peculiar operation: when loading packet data
into the transmission (TX) buffer of the emulated radio transceiver:
MSPSim, when emulating the mote, performs this TX buffer loading at
a different speed than the actual hardware.

Consequently, we wrote a simple test program, whose only role is to send
data packets of various sizes, chosen amongst:
\begin{itemize}
\item \emph{moderate} size, with a payload of 30 bytes;
\item \emph{medium} size, with a payload of 60 bytes;
\item \emph{large} size, with a payload of 110 bytes (that is:
      near the maximum size of 127 bytes for IEEE 802.15.4 packets).
\end{itemize}
The actually transmitted packet have 11 bytes of overhead (headers and
checksum) beyond their payload.

This program sends consecutively 50 packets of the chosen size, at the rate
of 1 packet per second, for each run: we thus computed the mean and
standard deviation for such a group of 50 packets for each setup.
The measured value is the duration or ``delay'' taken to load one of these
packets into the TX buffer of the radio transceiver.

In addition, many runs have been executed for each setup, so as to verify
the stability of the results.

It has been compiled for, and run on the following hardware platforms:
\begin{itemize}
\item the well-known SkyMote/TelosB mote, powered by a MSP430F1611 MCU;
\item the more recent Zolertia Z1 mote powered by a MSP430 F2617 MCU.
\end{itemize}
Both devices have the same CC2420 radio transceiver.

These values are given for different operating systems---the well-known
Contiki OS, as well as the more recent RIOT OS~\cite{RIOT} which is also
specialized in WSN---as well as for two kinds of SPI drivers:
\begin{itemize}
\item a standard SPI model, which waits for every transmitted byte to be
validated by the hardware SPI interface before sending the next one:
we also call it the ``safe'' SPI access model, since it allows to detect
any problem that can occur during transmission on the SPI bus; this is
the write method used by default by the SPI driver of RIOT OS;
\item a so-called ``fast write'' SPI model, where a byte is written to
the bus every time the SPI hardware TX register is empty, without waiting
for the validation signals for the previous byte to be returned; this is
the write method used by the SPI driver of Contiki OS. While this allows
for faster writes on the SPI bus, it makes transfers---at least in
theory---less reliable.
\end{itemize}

For completing the results obtained with default SPI drivers for both OSes,
we modified the RIOT OS SPI driver to make it use the ``fast write''
SPI model, and thus obtained an additional setup for our tests.

The results of the comparison between execution on simulated motes
in COOJA/MSPSim and on physical hardware are shown in
Table~\ref{TblTXPktLoadDelaysSkyTelosB} for SkyMote/TelsoB hardware,
and in Table~\ref{TblTXPktLoadDelaysZ1} for Zolertia Z1 hardware.

Note that in both tables, delay values are given in ``ticks'' of timers
incrementing at a rate of 32,768~Hz. The unit is thus a fixed period of
time equal to about 30.5~microseconds.


\newcommand{\tabtitle}[1]{\multicolumn{8}{c}{\bfseries #1}}
\newcommand{\ticks}[1]{#1 ticks}
\newcommand{\moy}[1]{#1}
\newcommand{\ect}[1]{#1}
\newcommand{\estus}[1]{($\approx$ #1 $\mu$sec.)}
\newcommand{\prctv}[1]{$\approx$ #1\% exp. value}

\begin{table*}[htb]
\caption{Delays Observed for Loading One Packet into CC2420 TX Buffer
of a SkyMote/TelosB Mote, Using Various Software Setups.}
\label{TblTXPktLoadDelaysSkyTelosB}
\centering

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with Contiki OS}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{6.4} & \ect{0.50} & \moy{7.2} & \ect{0.40}
          & \ticks{--0.8}  & \estus{24} & \prctv{11} \\
 Medium   & \moy{10.7} & \ect{0.46} & \moy{12.7} & \ect{0.48}
          & \ticks{--2.0}  & \estus{60} & \prctv{15} \\
 Large    & \moy{18.0} & \ect{0.00} & \moy{20.6} & \ect{0.49}
          & \ticks{--2.6}  & \estus{80} & \prctv{13} \\
\hline
\end{tabular}

\vspace{4pt}

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with RIOT OS (standard ``safe'' SPI driver)}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{58.0} & \ect{0.00} & \moy{50.3} & \ect{0.46}
          & \ticks{7.7}  & \estus{235} & \prctv{15} \\
 Medium   & \moy{85.2} & \ect{0.39} & \moy{73.6} & \ect{0.50}
          & \ticks{11.6}  & \estus{355} & \prctv{16} \\
 Large    & \moy{131.2} & \ect{0.39} & \moy{111.5} & \ect{0.51}
          & \ticks{19.7}  & \estus{601} & \prctv{18} \\
\hline
\end{tabular}

\vspace{4pt}

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with RIOT OS \emph{and} modified ``fast'' SPI writes}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{39.2} & \ect{0.39} & \moy{38.4} & \ect{0.49}
          & \ticks{0.8}  & \estus{24} & \prctv{2} \\
 Medium   & \moy{53.2} & \ect{0.39} & \moy{52.8} & \ect{0.40}
          & \ticks{0.4}  & \estus{12} & \prctv{1} \\
 Large    & \moy{76.2} & \ect{0.39} & \moy{75.2} & \ect{0.39}
          & \ticks{1.0}  & \estus{31} & \prctv{1} \\
\hline
\end{tabular}

\end{table*}


\begin{table*}[htb]
\caption{Delays Observed for Loading One Packet into CC2420 TX Buffer
of a Zolertia Z1 Mote, Using Various Software Setups.}
\label{TblTXPktLoadDelaysZ1}
\centering

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with Contiki OS}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{5.0} & \ect{0.14} & \moy{2.3} & \ect{0.44}
          & \ticks{2.8}  & \estus{84} & \prctv{122} \\
 Medium   & \moy{8.9} & \ect{0.27} & \moy{4.2} & \ect{0.37}
          & \ticks{4.8}  & \estus{145} & \prctv{114} \\
 Large    & \moy{14.0} & \ect{0.14} & \moy{7.2} & \ect{0.39}
          & \ticks{6.8}  & \estus{209} & \prctv{95} \\
\hline
\end{tabular}

\vspace{4pt}

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with RIOT OS (standard ``safe'' SPI driver)}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{46.0} & \ect{0.00} & \moy{16.2} & \ect{0.39}
          & \ticks{29.8}  & \estus{910} & \prctv{184} \\
 Medium   & \moy{69.0} & \ect{0.00} & \moy{24.2} & \ect{0.39}
          & \ticks{44.8}  & \estus{1368} & \prctv{185} \\
 Large    & \moy{106.8} & \ect{0.39} & \moy{38.0} & \ect{0.00}
          & \ticks{68.8}  & \estus{2100} & \prctv{181} \\
\hline
\end{tabular}

\vspace{4pt}

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with RIOT OS \emph{and} modified ``fast'' SPI writes}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{27.0} & \ect{0.00} & \moy{10.0} & \ect{0.00}
          & \ticks{17.0} & \estus{519} & \prctv{170} \\
 Medium   & \moy{35.0} & \ect{0.00} & \moy{13.2} & \ect{0.39}
          & \ticks{21.8} & \estus{665} & \prctv{166} \\
 Large    & \moy{49.0} & \ect{0.00} & \moy{18.2} & \ect{0.39}
          & \ticks{30.8} & \estus{941} & \prctv{170} \\
\hline
\end{tabular}

\end{table*}

\medskip

The results with ``standard'' setups show that:
\begin{itemize}
\item for the Z1 hardware platform, the results are just catastrophic:
the difference between experimental and simulation values represent
an overestimation that amounts from 100\% to almost 200\% of the actual
delay! Such overestimated values are clearly unusable for performance
evaluation purposes;
\item for the SkyMote/Telosb, the differences are much smaller, but still
above 10\% for Contiki OS, and even 15\% for the RIOT OS setup, which is not
negligible for an accurate performance evaluation work; moreover, these
differences can go in both directions (that is: under- and over-estimation),
which makes the timing inaccuracy of simulations quite unpredictable and
thus hard to estimate and correct without a comparison with experimentation
on actual hardware.
\end{itemize}

With the modified RIOT OS setup (``fast SPI''), we can see that:
\begin{itemize}
\item there is absolutely no accuracy improvement for the Z1 platform,
the timing results obtained are still overestimated by about 170\% of
the actual value!
\item for the SkyMote/TelosB platform, the situation improves, leading
to the obtention of quite accurate results (2\% or less of inaccuracy).
\end{itemize}

This gives us leads about the cause of this inaccuracy problem: since it
is largely dependent on the hardware platform simulated \emph{and} the method
used to write on the SPI bus, it is probably not (mainly) due to the
emulation of the CC2420 transceiver chip, but rather to the estimation of
the timing of SPI bus transfers, made at the MCU level. It is obvious that
the emulation of the MSP430F2617 (the MCU powering the Z1 mote) just
overestimates largely the SPI delays, while the emulation of the MSP430F1611
(from SkyMote/TelosB) performs better on that aspect.

We can suppose that the MSPSim software has probably been finely tuned for
MSP430F1611 emulation~--- especially for timing calibrations~---, while
MSP430F2617 emulation has been less thoroughly tested.

\medskip

We thus see that whatever the software environment used, we can make the
following observations about the inaccuracy in timing for the TX buffer
loading operation:
\begin{itemize}
\item for the Zolertia Z1 hardware platform, this inaccuracy is just huge:
the simulated loading delay is always 2 to 3 times larger than the actual
delay on hardware, whatever the setup (OS and SPI driver implementation)!
\item for the SkyMote/TelosB hardware platform, the inaccuracy is much less
important in absolute value, but less predictable, since it can go in both
senses: under-estimation or over-estimation of the actual delay on hardware.
Moreover, this inaccuracy can go up to 15\% of the real value with Contiki
OS (and even more when running RIOT OS) which is not a negligible fraction.
\end{itemize}
This just makes the time-related results obtained with COOJA/ MSPSim
simulations unreliable for performance evaluation purposes, particularly
on Zolertia Z1, but also on the very popular SkyMote/TelosB hardware platform.

\medskip

When computing the relative weight of TX buffer loading in total packet
transmission duration, we see that the TX load delay always represent at
least 10\% ---up to more than 50\%---of the total duration taken to send
a packet, especially when running an OS different from Contiki (see Table
\ref{TblTXRelWeight} for detailed results).
Such an inaccuracy in the evaluation of packet TX delay is obviously bound
to have strong consequences on the reliability of performance evaluations
made with COOJA/MSPSim simulations.

\begin{table*}[htbp]
\caption{Relative Weight of TX Buffer Loading in Packet Transmission Timings.}
\label{TblTXRelWeight}
\centering

\begin{tabular}{l|l|l|r|r|r|r}
\hline
HW Platform & WSN OS  & Pkt. Size
                  & Loading delay & TX delay & Total Delay
                  & Loading / Total (percentage) \\
\hline
SkyMote/TelosB    & Contiki & Moderate
                  &   196      & 1312     & 1508
                  & 13\% \\
SkyMote/TelosB    & Contiki & Medium
                  &   327      & 2272     & 2599
                  & 13\% \\
SkyMote/TelosB    & Contiki & Large
                  &   549      & 3872     & 4421
                  & 12\% \\
\hline
SkyMote/TelosB    & RIOT OS & Moderate
                  &  1770      & 1312     & 3082
                  & 57\% \\
SkyMote/TelosB    & RIOT OS & Medium
                  &  2599      & 2272     & 4871
                  & 53\% \\
SkyMote/TelosB    & RIOT OS & Large
                  &  4003      & 3872     & 7875
                  & 51\% \\
\hline
Zolertia Z1       & Contiki & Moderate
                  &   153      & 1312     & 1465
                  & 10\% \\
Zolertia Z1       & Contiki & Medium
                  &   272      & 2272     & 2544
                  & 11\% \\
Zolertia Z1       & Contiki & Large
                  &   428      & 3872     & 4300
                  & 10\% \\
\hline
Zolertia Z1       & RIOT OS & Moderate
                  &  1404      & 1312     & 2716
                  & 52\% \\
Zolertia Z1       & RIOT OS & Medium
                  &  2106   & 2272        & 4378
                  & 48\% \\
Zolertia Z1       & RIOT OS & Large
                  &  3260   & 3872        & 7132
                  & 46\% \\
\hline
\multicolumn{7}{l}{All delays in this table are in microseconds.}\\
\multicolumn{7}{l}{TX delays are computed using standard 802.15.4 rate
(32 $\mu$sec. per byte), with 11 bytes of overhead per packet.}\\
\end{tabular}
\end{table*}

\medskip

Moreover, since the problem seems to be caused by the emulation of
MCUs by the MSPSim emulator, we expect the vast majority of the other
MSP430-based motes and evaluation boards emulated by the Contiki 2.7
(i.e.: latest release) version of COOJA/MSPSim framework to be also similarly
impacted by this problem, at various levels.

Consequently, we believe that users of such devices should perform their
own tests to evaluate the possible inaccuracy and its impact on their work.
To help in that matter, we freely provide the programs we used to perform the
present work at the following URL.

\begin{center}
\texttt{\footnotesize https://github.com/rousselk/tim-inacc-tst-prg}
\end{center}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Consequences}
\label{consequences}

We looked in recent literature, and found many recent articles (that is:
published in year 2014 or later) relying on COOJA simulations to perform,
directly or indirectly, time-related performance evaluation of WSN projects
based on 802.15.4 networking.

Among them, we can see that most of these papers use virtual SkyMote/TelosB
nodes like
\cite{Constrain-Routing-Trees-2014},
\cite{Co-RPL-2014}, \cite{DINAS-2014},
\cite{Efficient-Distrib-Svc-Discovery-2014},
\cite{IETF-Routing-WSN-2014},
\cite{TinySDN-2014}, \cite{Trickle-L2-2014},
and \cite{Visual-Sensor-Networks-2014};
while some other use different, specific MSP430-based motes
(e.g.: EXP5438 for \cite{Key-Mgmt-2015}, or WisMote for
\cite{Lightweight-Multicast-Forwarding-2014}) whose sensibility
to the present inaccuracy problem is unknown to us.

We also saw one paper that relies on both simulations and experimental
results for timing-related performance evaluations: we especially found
\cite{Probing-Mech-wu-2015}, which also presents purely numerical,
MATLAB-produced results. We expect such articles, (much) less common,
to be less sensible to simulation inaccuracies.

Almost all of these papers present work related to higher layers of
WSN network stacks, especially routing protocols (like
\cite{Constrain-Routing-Trees-2014},
\cite{Co-RPL-2014}, \cite{IETF-Routing-WSN-2014},
and \cite{Trickle-L2-2014})
or application-level protocols (e.g.: \cite{DINAS-2014},
\cite{Efficient-Distrib-Svc-Discovery-2014},
\cite{Visual-Sensor-Networks-2014}, and \cite{Key-Mgmt-2015}).
Some can even present alternate network stacks (\cite{TinySDN-2014}).

\medskip

Such studies, which rely on COOJA/MSPSim emulation runs to evaluate
time-related performance on WSN, have a (potentially high) risk of
suffering from inexact results due to the timing inaccuracy described
hereabove, which may go from moderate up to critical bias.
in the latter case, the issue obviously goes as far as putting
the discussions and conclusions of these papers in jeopardy.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}
\label{conclusion}

In the present article, we provided the following contributions:
\begin{itemize}
\item we clearly showed that MSPSim emulation suffers from a serious timing
inaccuracy issue concerning SPI bus access, which especially impacts
communication between MCUs and radio transceivers---and thus, wireless
network operation---on WSN motes;
\item we described the extent of the problem with detailed experimentation
results---extent which happens to be serious, especially for the emulation
of the Zolertia Z1 hardware platform;
\item we provided serious clues about the cause of the issue, and
consequently showed the area to investigate for fixing it.
\end{itemize}

We briefly enumerated a list of many recently published articles in the
WSN domain whose results are potentially negatively impacted by this problem,
because they rely on COOJA/MSPSim simulations to evaluate their work.
The validity of such publications may be put in jeopardy by the
issue we describe here, especially when time-related results
obtained by simulation are involved.

\medskip

Until a fix is made and published to correct this timing inaccuracy
in the MSPSim emulator, we believe the only way to get robust and reliable
results concerning timing and time-related performance evaluation is
to perform tests on actual hardware, which will eliminate any bias
that can be introduced by inaccuracies in simulation.

Of course, such hardware tests are much more difficult, long and
costly to prepare, run and analyze.

Note that many published articles in the domain of WSNs, including
very recent publications, include simulations made with the COOJA/MSPSim
framework. This is clearly a testimony of the usefulness of the this
software package. That's why fixing the problem we describe in the present
paper by correcting MSPSim code as soon as possible is really important.

Note also that while the issue described here can impair the use of
COOJA/MSPSim as a performance evaluation tool, it does not affect its other
applications, like the ability to develop and debug WSN-related software much
more easily thanks to its emulation features.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\vfill
\balance
\bibliographystyle{abbrv}
\bibliography{TimingInacc}

\end{document}

