\documentclass[10pt]{ewsn-proc}

\usepackage[T1]{fontenc}
\usepackage{balance}

\numberofauthors{3}
\author{
\alignauthor K\'evin Roussel \\
        \affaddr{INRIA Nancy Grand-Est}\\
        \affaddr{615, rue du Jardin Botanique}\\
        \affaddr{54600 Villers-l\`es-Nancy, France}
       \email{kevin.roussel@inria.fr}
\alignauthor Ye-Qiong Song \\
        \affaddr{LORIA/INRIA Nancy Grand-Est}\\
        \affaddr{615, rue du Jardin Botanique}\\
        \affaddr{54600 Villers-l\`es-Nancy, France}
       \email{ye-qiong.song@loria.fr}
\alignauthor Olivier Zendra \\
        \affaddr{INRIA Nancy Grand-Est}\\
        \affaddr{615, rue du Jardin Botanique}\\
        \affaddr{54600 Villers-l\`es-Nancy, France}
       \email{olivier.zendra@inria.fr}
}

\title{Using Cooja for WSN Simulations: Some New Uses and Limits}

% Short paper for the NextMote workshop
\conferenceinfo{EWSN'16---NextMote Workshop}
               {February 15--17, 2016, Graz, Austria.}
\CopyrightYear{2015}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                               80 COLONNES                                %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\hyphenation{MSP-Sim}

\begin{abstract}
The Cooja/MSPSim network simulation framework is widely used for developing
and debugging, but also for performance evaluation of WSN projects.

When performing our own simulations with Cooja and MSPSim, we observed timing
inconsistencies with identical experimentations made on actual hardware.
Such inaccuracies clearly impair the use of the Cooja/MSPSim framework as
a performance evaluation tool, at least for time-related performance
parameters.

We will present in this paper, as our contributions, the detailed results of
our investigations on, as well as the consequences of this issue,
and give possible leads to fix or avoid it.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{introduction}

The research on Wireless Sensor Networks (WSN) and Internet of Things (IoT)
often resorts to simulation and/or emulation tools. It is indeed often
difficult to have enough devices (or ``nodes'' or ``motes'' as one might
call them) to perform the large-size tests often needed in this domain;
especially when these ``motes'' need to be instrumented to return enough
useful information to design, evaluate or debug projects based on this
kind of technology.

Thus, the development of innovative, ambitious projects such as those
that are the focus of the \emph{NextMote} workshop will surely need
such simulation/emulation tools, at least for the first steps of design
and test of new technologies, since the number of involved devices is
deemed to grow exponentially (for example: smart dusts, seeds or pollens),
and thus testing such a lot of miniaturized devices may be more and more
difficult.

There are many of such simulation/emulation tools (like, for example,
the OpenSim tool from the OpenWSN project~\cite{OpenWSN}). But currently,
one of the most used---if not \emph{the} most used---simulation/emulation
tool used in the WSN/IoT domain is the Cooja framework~\cite{Cooja}, which
includes the MSPSim and Avrora software to perform cycle-exact emulation
of ``motes''.

\medskip

The present paper is based on the two following subjects~:
\begin{enumerate}

\item The ability, actually tested and used pervasively, to use Cooja
to run programs that are absolutely not designed with, nor even related to,
the Contiki operating system. Any program running on the microcontroller
(MCU) architectures supported by the embedded emulators of Cooja---MSPSim
and Avrora---can be simulated (with the use of a trivial trick).

\item The result inaccuracies we discovered while using Cooja simulations
for testing our own WSN-based projects. Since Cooja is widely used,
especially for evaluating performances of WSN or IoT-based projects,
such inaccuracies may have strong consequences on the validity of
the many publications making use of this framework.

\end{enumerate}

\bigskip

In this paper, after a brief reminder about Cooja and MSPSim in the
following section~\ref{coojaMspsim}, our contributions firstly consist in
describing, in section~\ref{newUses}, how the Cooja Framework is absolutely
not limited to simulation of Contiki-based projects, but can---thanks to
its emulation features---run any program built for one of the systems
supported by its embedded emulators. \\
We then provide---in section~\ref{results}---in a detailed description
of this timing inaccuracy problem, using a significant set of comparisons
between simulations and experimentations on hardware; we then use
these results to provide clues about the origin of this issue, and
possible means to fix or avoid it. \\
Then in section~\ref{consequences} we see this problem's consequences
on current WSN/IoT-related literature, in terms of robustness and
reliability of the articles relying on such simulations. \\
Finally, we draw in section~\ref{conclusion} some conclusions from all
of these contributions as an end to the present article.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Cooja and MSPSim}
\label{coojaMspsim}

Provided by the Contiki OS project~\cite{ContikiOS}, the Cooja network
simulator~\cite{Cooja} has become a widely used tool in the domain of
Wireless Sensor Networks (WSN). The research community especially uses
it extensively to perform simulations of small to relatively large wireless
networks of connected devices embedding sensors and/or actuators, commonly
named \emph{``motes''}, and thus to develop, debug and evaluate projects
based in the WSN technology.

The use of simulations is especially useful for performing virtual runs
on large sensor networks, comprising a large number of motes that would
be difficult, long and costly to operate with actual hardware.

\medskip

Cooja itself is a Java-based application, providing three main features:
\begin{enumerate}
\item a graphical user interface (GUI, based on Java's standard Swing toolkit)
to design, run, and analyze WSN simulations;
\item simulation of the radio medium underlying the wireless communications
of sensor networks;
\item an extensible framework, which allows integration of external tools
to provide additional features to the Cooja application.
\end{enumerate}

\medskip

This last feature is used to allow Cooja to actually emulate the various
motes constituting the WSNs. It indeed embeds and uses dedicated emulator
programs that perform cycle-accurate emulation of the chips with which motes
are built: microcontroller units (MCUs), radio transceivers, etc.

This emulation mechanism is one of the main strong assets of Cooja:
thanks to it, very fine-grained, precise and low-level simulations
can be performed; this is why Cooja has become a tool of choice especially
for debugging and evaluating WSN-related software (which happens to be
often based on Contiki OS).

Current versions of Cooja make use of two different emulator software
packages: Avrora~\cite{Avrora} for emulation of Atmel AVR-based devices,
and MSPSim~\cite{MSPSim} for emulation of TI MSP430-based devices.

(Also note that in the future, the structure of Cooja would allow it
to include more emulators, dedicated to other architectures: one might
especially think to the ARM Cortex-M architecture which is more and
more used in ``motes'' and other embedded devices.)

Of these two emulators, MSPSim is currently the most used in literature
including Cooja-based simulations, since motes based on MSP430 MCUs are
more commonly distributed and used: we can especially think to the pervasive
TelosB/SkyMote family, or to Zolertia's Z1 platform. Since the latter
devices are the hardware we use, the present paper will principally
focus on the MSPSim emulator.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Using Cooja and MSPSim: Not Only for Contiki!}
\label{newUses}

While Cooja has been designed and built by the Contiki project to perform
simulations of Contiki-based networks of motes, its structure is actually
not tied at all to this operating system.

As explained in the previous section~\ref{coojaMspsim}, the Cooja Java
application itself only provides--- besides a GUI---the simulation of the
radio medium, which by itself is, of course, totally independent of
anything but signal transmission: It only cares about signal strength,
propagation, diffusion and interferences. In other words, nothing related
to the motes themselves, and \textit{a fortiori} the programs they run
is of any slightest influence here.

All the handling of the motes and the programs they run are handled by
the emulators software embedded with Cooja, the latter only process the
radio signals that the emulated devices emit and receive on the virtual
radio medium, according to the way the said medium is simulated.
That is: All that happens inside the motes themselves is actually
ignored by Cooja itself, and is handled by the emulators.

An emulator software being, by definition, a virtual instance of an
hardware piece, it is supposed to execute---as much as possible---the
same way that the hardware it emulates. Since motes like the TelosB/SkyMote
or Zolertia Z1 are in no way tied to the Contiki OS (they are powered
by general-purpose MCUs), nor are their emulators like MSPSim.

Thus, like one can run many OSes like TinyOS, Contiki, RIOT OS, Nano-RK,
etc. on these motes, so should we be able to run the same variety
of operating systems on these motes' emulators.

Like one will see in the next sections of the present paper, we were able
to run RIOT OS applications using Cooja/MSPSim without problem. We are
also convinced that running other OSes like, for example, Nano-RK or
FreeRTOS under Cooja simulations would work as well, provided the emulated
motes are supported by the versions of MSPSim and Avrora provided with
Cooja.

\medskip

To run our RIOT OS applications under Cooja, we only had to perform one
very simple trick: MSPSim expects to run executables whose name extension
corresponds to the emulated platform; for example:
``\texttt{executable.sky}'' for the SkyMote/TelosB family, or
``\texttt{executable.z1}'' for the Zolertia Z1. The Contiki build system
(\texttt{Makefiles}) is designed to give to the compiled executables
such ad-hoc extensions automatically. RIOT OS build system, on the
contrary, always produces executables named like ``\texttt{executable.elf}''
(since the compilation toolchain, which happens to be the standard GNU
toolchain for both OSes, produces executables in the well-known ELF
executable format). To be able to run RIOT OS executables under Cooka
simulations, we thus had to change their extension accordingly to the
target platform to respect the Contiki build system naming scheme---Cooja
will refuse to load a file as an executable without the appropriate
extension. Once this renaming done, running RIOT OS compiled executables
with Cooja simulations just works without any problem: Contiki build
system, apart from the specific naming scheme, also produces standard
ELF executables, built with the appropriate version of the GCC toolchain
(i.e.: \texttt{gcc-msp430} or \texttt{gcc-avr}, according to the platform).
Note that we were able to use the standard Debian-packaged version of
these cross-compilers to create executables for both Contiki OS and
RIOT OS without any problem.

To sum it up, the Contiki build system produces standard ELF-formatted
executables, adapted to the target MCU architecture. Any WSN OS producing
such standard ELF executables should thus be able to be simulated/emulated
as well under Cooja simulations. The only manipulation needed is a simple
renaming trick as explained in the previous paragraph, so as to follow
Cooja naming scheme linking executable name extension and platform
(``\texttt{exe.z1}'' for the Zolertia Z1, ``\texttt{exe.sky}'' for
SkyMote/TelosB, and so on).

If one needs to know the extension that Cooja expects for a given hardware,
one should simply compile a simple Contiki example (like the ever classical
``\texttt{hello-world}'')  for the wanted hardware, and see what extension
the produced exectable has.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Timing Inaccuracy Problem in MSPSim}
\label{results}

When performing our own simulations with virtual networks of MSP430-based
motes, we noticed timing inaccuracies in comparison to experiences made
on actual hardware. More precisely, we noticed that our simulations showed
unexplained delays during packet transmission (TX) over the radio medium,
that weren't observed during similar experiences on physical motes.

We searched the literature, but we found no article related to any reported
inaccuracy in Cooja or MSPSim.

We then investigated the problem, and discovered the following results.

The problem is with the emulation of MSP430-powered, radio-enabled WSN
devices (a.k.a. ``motes'') by the MSPSim software package.

The differences appear on one peculiar operation: when loading packet data
into the transmission (TX) buffer of the emulated radio transceiver:
MSPSim, when emulating the mote, performs this TX buffer loading at
a different speed than the actual hardware.

Consequently, we wrote a simple test program, whose only role is to send
data packets of various sizes, chosen amongst:
\begin{itemize}
\item \emph{moderate} size, with a payload of 30 bytes;
\item \emph{medium} size, with a payload of 60 bytes;
\item \emph{large} size, with a payload of 110 bytes (that is:
      near the maximum size of 127 bytes for IEEE 802.15.4 packets).
\end{itemize}

\medskip

The actually transmitted packet have 11 bytes of overhead (headers and
checksum) beyond their payload.

This program sends consecutively 50 packets of the chosen size, at the rate
of 1 packet per second, for each run: we thus computed the mean and
standard deviation for such a group of 50 packets for each setup.
The measured value is the duration or ``delay'' taken to load one of these
packets into the TX buffer of the radio transceiver.

In addition, many runs have been executed for each setup, so as to verify
the stability of the results.

It has been compiled for, and run on the following hardware platforms:
\begin{itemize}
\item the well-known SkyMote/TelosB mote, powered by a MSP430F1611 MCU;
\item the more recent Zolertia Z1 mote powered by a MSP430 F2617 MCU.
\end{itemize}

\smallskip

Both devices have the same CC2420 radio transceiver.

\medskip

These values are given for different operating systems---the well-known
Contiki OS, as well as the more recent RIOT OS~\cite{RIOT} which is also
specialized in WSN---as well as for two kinds of SPI drivers:
\begin{itemize}
\item a standard SPI model, which waits for every transmitted byte to be
validated by the hardware SPI interface before sending the next one:
we also call it the ``safe'' SPI access model, since it allows to detect
any problem that can occur during transmission on the SPI bus; this is
the write method used by default by the SPI driver of RIOT OS;
\item a so-called ``fast write'' SPI model, where a byte is written to
the bus every time the SPI hardware TX register is empty, without waiting
for the validation signals for the previous byte to be returned; this is
the write method used by the SPI driver of Contiki OS. While this allows
for faster writes on the SPI bus, it makes transfers---at least in
theory---less reliable.
\end{itemize}

\medskip

For completing the results obtained with default SPI drivers for both OSes,
we modified the RIOT OS SPI driver to make it use the ``fast write''
SPI model, and thus obtained an additional setup for our tests.

\medskip

The results of the comparison between execution on simulated motes
in Cooja/MSPSim and on physical hardware are shown in
Table~\ref{TblTXPktLoadDelaysSkyTelosB} for SkyMote/TelsoB hardware,
and in Table~\ref{TblTXPktLoadDelaysZ1} for Zolertia Z1 hardware.

Note that in both tables, delay values are given in ``ticks'' of timers
incrementing at a rate of 32,768~Hz. The unit is thus a fixed period of
time equal to about 30.5~microseconds.


\newcommand{\tabtitle}[1]{\multicolumn{8}{c}{\bfseries #1}}
\newcommand{\ticks}[1]{#1 ticks}
\newcommand{\moy}[1]{#1}
\newcommand{\ect}[1]{#1}
\newcommand{\estus}[1]{($\approx$ #1 $\mu$sec.)}
\newcommand{\prctv}[1]{$\approx$ #1\% exp. value}


\begin{table*}[htb]
\caption{Delays Observed for Loading One Packet into CC2420 TX Buffer
of a SkyMote/TelosB Mote, Using Various Software Setups.}
\label{TblTXPktLoadDelaysSkyTelosB}
\centering

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with Contiki OS}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{6.4} & \ect{0.50} & \moy{7.2} & \ect{0.40}
          & \ticks{--0.8}  & \estus{24} & \prctv{11} \\
 Medium   & \moy{10.7} & \ect{0.46} & \moy{12.7} & \ect{0.48}
          & \ticks{--2.0}  & \estus{60} & \prctv{15} \\
 Large    & \moy{18.0} & \ect{0.00} & \moy{20.6} & \ect{0.49}
          & \ticks{--2.6}  & \estus{80} & \prctv{13} \\
\hline
\end{tabular}

\vspace{4pt}

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with RIOT OS (standard ``safe'' SPI driver)}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{58.0} & \ect{0.00} & \moy{50.3} & \ect{0.46}
          & \ticks{7.7}  & \estus{235} & \prctv{15} \\
 Medium   & \moy{85.2} & \ect{0.39} & \moy{73.6} & \ect{0.50}
          & \ticks{11.6}  & \estus{355} & \prctv{16} \\
 Large    & \moy{131.2} & \ect{0.39} & \moy{111.5} & \ect{0.51}
          & \ticks{19.7}  & \estus{601} & \prctv{18} \\
\hline
\end{tabular}

\vspace{4pt}

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with RIOT OS \emph{and} modified ``fast'' SPI writes}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{39.2} & \ect{0.39} & \moy{38.4} & \ect{0.49}
          & \ticks{0.8}  & \estus{24} & \prctv{2} \\
 Medium   & \moy{53.2} & \ect{0.39} & \moy{52.8} & \ect{0.40}
          & \ticks{0.4}  & \estus{12} & \prctv{1} \\
 Large    & \moy{76.2} & \ect{0.39} & \moy{75.2} & \ect{0.39}
          & \ticks{1.0}  & \estus{31} & \prctv{1} \\
\hline
\end{tabular}

\end{table*}


\begin{table*}[htb]
\caption{Delays Observed for Loading One Packet into CC2420 TX Buffer
of a Zolertia Z1 Mote, Using Various Software Setups.}
\label{TblTXPktLoadDelaysZ1}
\centering

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with Contiki OS}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{5.0} & \ect{0.14} & \moy{2.3} & \ect{0.44}
          & \ticks{2.8}  & \estus{84} & \prctv{122} \\
 Medium   & \moy{8.9} & \ect{0.27} & \moy{4.2} & \ect{0.37}
          & \ticks{4.8}  & \estus{145} & \prctv{114} \\
 Large    & \moy{14.0} & \ect{0.14} & \moy{7.2} & \ect{0.39}
          & \ticks{6.8}  & \estus{209} & \prctv{95} \\
\hline
\end{tabular}

\vspace{4pt}

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with RIOT OS (standard ``safe'' SPI driver)}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{46.0} & \ect{0.00} & \moy{16.2} & \ect{0.39}
          & \ticks{29.8}  & \estus{910} & \prctv{184} \\
 Medium   & \moy{69.0} & \ect{0.00} & \moy{24.2} & \ect{0.39}
          & \ticks{44.8}  & \estus{1368} & \prctv{185} \\
 Large    & \moy{106.8} & \ect{0.39} & \moy{38.0} & \ect{0.00}
          & \ticks{68.8}  & \estus{2100} & \prctv{181} \\
\hline
\end{tabular}

\vspace{4pt}

\begin{tabular}{l|rr|rr|rcl}
\tabtitle{Results with RIOT OS \emph{and} modified ``fast'' SPI writes}\\
\hline
Pkt. Size & \multicolumn{2}{c|}{Cooja Simulation (ticks)}
          & \multicolumn{2}{c|}{Hardware Experiment (ticks)}
          & \multicolumn{3}{c}{Mean Difference} \\
\hline
          & Mean & Std. Dev. & Mean & Std. Dev. & \\
\hline
 Moderate & \moy{27.0} & \ect{0.00} & \moy{10.0} & \ect{0.00}
          & \ticks{17.0} & \estus{519} & \prctv{170} \\
 Medium   & \moy{35.0} & \ect{0.00} & \moy{13.2} & \ect{0.39}
          & \ticks{21.8} & \estus{665} & \prctv{166} \\
 Large    & \moy{49.0} & \ect{0.00} & \moy{18.2} & \ect{0.39}
          & \ticks{30.8} & \estus{941} & \prctv{170} \\
\hline
\end{tabular}

\end{table*}


\medskip

The results with ``standard'' setups show that:
\begin{itemize}
\item for the Z1 hardware platform, the results are just catastrophic:
the difference between experimental and simulation values represent
an overestimation that amounts from 100\% to almost 200\% of the actual
delay! Such overestimated values are clearly unusable for performance
evaluation purposes;
\item for the SkyMote/Telosb, the differences are much smaller, but still
above 10\% for Contiki OS, and even 15\% for the RIOT OS setup, which is not
negligible for an accurate performance evaluation work; moreover, these
differences can go in both directions (that is: under- and over-estimation),
which makes the timing inaccuracy of simulations quite unpredictable and
thus hard to estimate and correct without a comparison with experimentation
on actual hardware.
\end{itemize}

\bigskip

With the modified RIOT OS setup (``fast SPI''), we can see that:
\begin{itemize}
\item there is absolutely no accuracy improvement for the Z1 platform,
the timing results obtained are still overestimated by about 170\% of
the actual value!
\item for the SkyMote/TelosB platform, the situation improves, leading
to the obtention of quite accurate results (2\% or less of inaccuracy).
\end{itemize}

\medskip

This gives us leads about the cause of this inaccuracy problem: since it
is largely dependent on the hardware platform simulated \emph{and} the method
used to write on the SPI bus, it is probably not (mainly) due to the
emulation of the CC2420 transceiver chip, but rather to the estimation of
the timing of SPI bus transfers, made at the MCU level. \\
It is obvious that the emulation of the MSP430F2617 (the MCU powering the
Z1 mote) just overestimates largely the SPI delays, while the emulation
of the MSP430F1611 (from SkyMote/TelosB) performs better on that aspect.

We can suppose that the MSPSim software has probably been finely tuned for
MSP430F1611 emulation~--- especially for timing calibrations~---, while
MSP430F2617 emulation has been less thoroughly tested.

\medskip

We thus see that whatever the software environment used, we can make the
following observations about the inaccuracy in timing for the TX buffer
loading operation:
\begin{itemize}
\item for the Zolertia Z1 hardware platform, this inaccuracy is just huge:
the simulated loading delay is always 2 to 3 times larger than the actual
delay on hardware, whatever the setup (OS and SPI driver implementation)!
\item for the SkyMote/TelosB hardware platform, the inaccuracy is much less
important in absolute value, but less predictable, since it can go in both
senses: under-estimation or over-estimation of the actual delay on hardware.
Moreover, this inaccuracy can go up to 15\% of the real value with Contiki
OS (and even more when running RIOT OS) which is not a negligible fraction.
\end{itemize}

\bigskip

This just makes the time-related results obtained with Cooja/ MSPSim
simulations unreliable for performance evaluation purposes, particularly
on Zolertia Z1, but also on the very popular SkyMote/TelosB hardware platform.

\medskip

When computing the relative weight of TX buffer loading in total packet
transmission duration, we see that the TX load delay always represent at
least 10\% ---up to more than 50\%---of the total duration taken to send
a packet, especially when running an OS different from Contiki (see Table
\ref{TblTXRelWeight} for detailed results).
Such an inaccuracy in the evaluation of packet TX delay is obviously bound
to have strong consequences on the reliability of performance evaluations
made with Cooja/MSPSim simulations.

\begin{table*}[htbp]
\caption{Relative Weight of TX Buffer Loading in Packet Transmission Timings.}
\label{TblTXRelWeight}
\centering

\begin{tabular}{l|l|l|r|r|r|r}
\hline
HW Platform & WSN OS  & Pkt. Size
                  & Loading delay & TX delay & Total Delay
                  & Loading / Total (percentage) \\
\hline
SkyMote/TelosB    & Contiki & Moderate
                  &   196      & 1312     & 1508
                  & 13\% \\
SkyMote/TelosB    & Contiki & Medium
                  &   327      & 2272     & 2599
                  & 13\% \\
SkyMote/TelosB    & Contiki & Large
                  &   549      & 3872     & 4421
                  & 12\% \\
\hline
SkyMote/TelosB    & RIOT OS & Moderate
                  &  1770      & 1312     & 3082
                  & 57\% \\
SkyMote/TelosB    & RIOT OS & Medium
                  &  2599      & 2272     & 4871
                  & 53\% \\
SkyMote/TelosB    & RIOT OS & Large
                  &  4003      & 3872     & 7875
                  & 51\% \\
\hline
Zolertia Z1       & Contiki & Moderate
                  &   153      & 1312     & 1465
                  & 10\% \\
Zolertia Z1       & Contiki & Medium
                  &   272      & 2272     & 2544
                  & 11\% \\
Zolertia Z1       & Contiki & Large
                  &   428      & 3872     & 4300
                  & 10\% \\
\hline
Zolertia Z1       & RIOT OS & Moderate
                  &  1404      & 1312     & 2716
                  & 52\% \\
Zolertia Z1       & RIOT OS & Medium
                  &  2106   & 2272        & 4378
                  & 48\% \\
Zolertia Z1       & RIOT OS & Large
                  &  3260   & 3872        & 7132
                  & 46\% \\
\hline
\multicolumn{7}{l}{All delays in this table are in microseconds.}\\
\multicolumn{7}{l}{TX delays are computed using standard 802.15.4 rate
(32 $\mu$sec. per byte), with 11 bytes of overhead per packet.}\\
\end{tabular}
\end{table*}

\medskip

Moreover, since the problem seems to be caused by the emulation of
MCUs by the MSPSim emulator, we expect the vast majority of the other
MSP430-based motes and evaluation boards emulated by the Contiki 2.7
(i.e.: latest release) version of Cooja/MSPSim framework to be also similarly
impacted by this problem, at various levels.

Consequently, we believe that users of such devices should perform their
own tests to evaluate the possible inaccuracy and its impact on their work.
To help in that matter, we freely provide the programs we used to perform the
present work at the following URL:

\medskip

\begin{center}
\texttt{\textbf{\small https://github.com/rousselk/tim-inacc-tst-prg}}
\end{center}

\bigskip


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Consequences}
\label{consequences}

We looked in recent literature, and found many recent articles (that is:
published in year 2014 or later) relying on Cooja simulations to perform,
directly or indirectly, time-related performance evaluation of WSN projects
based on 802.15.4 networking.

Among them, we can see that most of these papers use virtual SkyMote/TelosB
nodes like
\cite{Constrain-Routing-Trees-2014},
\cite{Co-RPL-2014}, \cite{DINAS-2014},
\cite{Efficient-Distrib-Svc-Discovery-2014},
\cite{IETF-Routing-WSN-2014},
\cite{TinySDN-2014}, \cite{Trickle-L2-2014},
and \cite{Visual-Sensor-Networks-2014};
while some other use different, specific MSP430-based motes
(e.g.: EXP5438 for \cite{Key-Mgmt-2015}, or WisMote for
\cite{Lightweight-Multicast-Forwarding-2014}) whose sensibility
to the present inaccuracy problem is unknown to us.

\smallskip

We also saw one paper that relies on both simulations and experimental
results for timing-related performance evaluations: we especially found
\cite{Probing-Mech-wu-2015}, which also presents purely numerical,
MATLAB-produced results. We expect such articles, (much) less common,
to be less sensible to simulation inaccuracies.

\smallskip

Almost all of these papers present work related to higher layers of
WSN network stacks, especially routing protocols (like
\cite{Constrain-Routing-Trees-2014},
\cite{Co-RPL-2014}, \cite{IETF-Routing-WSN-2014},
and \cite{Trickle-L2-2014})
or application-level protocols (e.g.: \cite{DINAS-2014},
\cite{Efficient-Distrib-Svc-Discovery-2014},
\cite{Visual-Sensor-Networks-2014}, and \cite{Key-Mgmt-2015}).
Some can even present alternate network stacks (\cite{TinySDN-2014}).

\bigskip

Such studies, which rely on Cooja/MSPSim emulation runs to evaluate
time-related performance on WSN, have a (potentially high) risk of
suffering from inexact results due to the timing inaccuracy described
hereabove, which may go from moderate up to critical bias.
in the latter case, the issue obviously goes as far as putting
the discussions and conclusions of these papers in jeopardy.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}
\label{conclusion}

In the present article, we provided the following contributions:
\begin{itemize}
\item We proved that the Cooja Framework is in no way limited to simulations
of systems running Contiki OS, but can---thanks to the use of embedded
software to perform cycle-exact emulation of devices--- run any program
designed for one of the emulated architectures, whatever the OS used
(or not).
\item We clearly showed that MSPSim emulation suffers from a serious timing
inaccuracy issue concerning SPI bus access, which especially impacts
communication between MCUs and radio transceivers---and thus, wireless
network operation---on WSN motes;\\
we described the extent of the problem with detailed experimentation
results---extent which happens to be serious, especially for the emulation
of the Zolertia Z1 hardware platform;\\
we provided serious clues about the cause of the issue, and
consequently showed the area to investigate for fixing it.
\item We briefly enumerated a list of many recently published articles in the
WSN domain whose results are potentially negatively impacted by this problem,
because they rely on Cooja/MSPSim simulations to evaluate their work.
The validity of such publications may be put in jeopardy by the
issue we describe here, especially when time-related results
obtained by simulation are involved.
\end{itemize}

\medskip

Until a fix is made and published to correct this timing inaccuracy
in the MSPSim emulator, we believe the only way to get robust and reliable
results concerning timing and time-related performance evaluation is
to perform tests on actual hardware, which will eliminate any bias
that can be introduced by inaccuracies in simulation.

Of course, such hardware tests are much more difficult, long and
costly to prepare, run and analyze.

\medskip

Note that many published articles in the domain of WSNs, including
very recent publications, include simulations made with the Cooja/MSPSim
framework. This is clearly a testimony of the usefulness of the this
software package. That's why fixing the problem we describe in the present
paper by correcting MSPSim code as soon as possible is really important.

\bigskip

Note also that while the issue described here can impair the use of
Cooja/MSPSim as a performance evaluation tool, it does not affect its other
applications, like the ability to develop and debug WSN-related software much
more easily thanks to its emulation features.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\balance

\bibliographystyle{abbrv}
\bibliography{TimingInacc}

\end{document}

